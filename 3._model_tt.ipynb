{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pickle.load(open(\"lgbm_v_18_fold_all.bin\",'rb')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.num_trees()\n",
    "# model.feature_name()\n",
    "# model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import random\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import feather\n",
    "import os\n",
    "import glob\n",
    "import csv   \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/pgut682g/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/pgut682g/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/pgut682g/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/pgut682g/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/pgut682g/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/pgut682g/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dropout, Dense, Embedding, SpatialDropout1D, concatenate, BatchNormalization, Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.losses import mean_squared_error as mse_loss\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/pgut682g/Projects/Projects/ashare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.9 s, sys: 39.6 s, total: 53.5 s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = feather.read_dataframe(path + '/data-vol-3/train_filled_na.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.7 s, sys: 1min 18s, total: 1min 44s\n",
      "Wall time: 4min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_for_train = feather.read_dataframe(path + '/data-vol-3/test_filled_all_na.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train train data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 2718.42 Mb (64.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['hour'] = train['utc_time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Education, Lodging/residential, Office, Entertainment/public assembly, Other, ..., Healthcare, Utility, Technology/science, Manufacturing/industrial, Services]\n",
       "Length: 16\n",
       "Categories (16, object): [Education, Lodging/residential, Office, Entertainment/public assembly, ..., Utility, Technology/science, Manufacturing/industrial, Services]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"primary_use\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  6,  1,  7, 11,  8,  9, 15,  2, 10,  3, 14, 13,  5, 12])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_train[\"primary_use\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train[\"primary_use\"] = le.fit_transform(train[\"primary_use\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"primary_use\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['meter',\n",
    " 'primary_use',\n",
    " 'building_id',\n",
    " 'site_id',              \n",
    "]\n",
    "\n",
    "numericals = ['square_feet',\n",
    " 'floor_count',\n",
    " 'new_floor_count',\n",
    " 'is_holiday',\n",
    " 'hour',\n",
    " 'weekday_cos',\n",
    " 'weekday_sin',\n",
    " 'weekday',\n",
    " 'hour_cos',\n",
    " 'hour_sin',\n",
    " 'year_cos',\n",
    " 'year_sin',\n",
    " 'is_day_saving',\n",
    " 'air_temperature',\n",
    " 'age',\n",
    " 'dew_temperature',\n",
    " 'sea_level_pressure',\n",
    " 'new_sea_level_pressure',\n",
    " 'new_dew_temperature',\n",
    " 'new_wind_speed',\n",
    " 'new_air_temperature',\n",
    " 'humidity',\n",
    " 'latitude',\n",
    " 'irradiance',\n",
    " 'feels_like',\n",
    " 'new_feels_like',\n",
    " 'radiation',\n",
    " 'air_temperature_mean_lag72',\n",
    " 'air_temperature_max_lag72',\n",
    " 'air_temperature_min_lag72',\n",
    " 'air_temperature_std_lag72',\n",
    " 'cloudCover_mean_lag72',\n",
    " 'cloudCover_std_lag72',\n",
    " 'new_wind_direction_cos',\n",
    " 'new_wind_direction_sin']\n",
    "\n",
    "feat_cols = categoricals + numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['year_built'].fillna(-999, inplace=True)\n",
    "train['new_year_built'].fillna(-999, inplace=True)\n",
    "train['age'] = train['utc_time'].dt.year - train['year_built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log1p(train[\"meter_reading\"])\n",
    "\n",
    "del train[\"meter_reading\"] \n",
    "#train = train.drop(drop_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={\"utc_time\":\"timestamp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train[(train['suspicious_1'] != 1) & (train['suspicious_2'] != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(dense_dim_1=128, dense_dim_2=64, dense_dim_3=32, dense_dim_4=16, \n",
    "dropout1=0.2, dropout2=0.1, dropout3=0.1, dropout4=0.1, lr=3e-4): \n",
    "\n",
    "    #Inputs\n",
    "    site_id = Input(shape=[1], name=\"site_id\")\n",
    "    building_id = Input(shape=[1], name=\"building_id\")\n",
    "    meter = Input(shape=[1], name=\"meter\")\n",
    "    primary_use = Input(shape=[1], name=\"primary_use\")\n",
    "    is_holiday = Input(shape=[1], name=\"is_holiday\")\n",
    "    is_day_saving = Input(shape=[1], name=\"is_day_saving\")\n",
    "    \n",
    "    hour_cos = Input(shape=[1], name=\"hour_cos\")\n",
    "    hour = Input(shape=[1], name=\"hour\")\n",
    "    air_temperature = Input(shape=[1], name=\"air_temperature\")\n",
    "    dew_temperature = Input(shape=[1], name=\"dew_temperature\")  \n",
    "    floor_count = Input(shape=[1], name=\"floor_count\")\n",
    "    new_floor_count = Input(shape=[1], name=\"new_floor_count\")\n",
    "    square_feet = Input(shape=[1], name=\"square_feet\")\n",
    "    irradiance = Input(shape=[1], name=\"irradiance\")\n",
    "    air_temperature_mean_lag72 = Input(shape=[1], name=\"air_temperature_mean_lag72\")\n",
    "    \n",
    "    weekday_cos = Input(shape=[1], name=\"weekday_cos\")\n",
    "    weekday_sin = Input(shape=[1], name=\"weekday_sin\")\n",
    "    weekday = Input(shape=[1], name=\"weekday\")\n",
    "    hour_sin = Input(shape=[1], name=\"hour_sin\")\n",
    "    year_cos = Input(shape=[1], name=\"year_cos\")\n",
    "    year_sin = Input(shape=[1], name=\"year_sin\")\n",
    "\n",
    "    age = Input(shape=[1], name=\"age\")\n",
    "    sea_level_pressure = Input(shape=[1], name=\"sea_level_pressure\")\n",
    "    new_sea_level_pressure = Input(shape=[1], name=\"new_sea_level_pressure\")\n",
    "    new_dew_temperature = Input(shape=[1], name=\"new_dew_temperature\")\n",
    "    new_wind_speed = Input(shape=[1], name=\"new_wind_speed\")\n",
    "    new_air_temperature = Input(shape=[1], name=\"new_air_temperature\")\n",
    "    humidity = Input(shape=[1], name=\"humidity\")\n",
    "    latitude = Input(shape=[1], name=\"latitude\")\n",
    "    feels_like = Input(shape=[1], name=\"feels_like\")\n",
    "    new_feels_like = Input(shape=[1], name=\"new_feels_like\")\n",
    "    radiation = Input(shape=[1], name=\"radiation\")\n",
    "    air_temperature_max_lag72 = Input(shape=[1], name=\"air_temperature_max_lag72\")\n",
    "    air_temperature_min_lag72 = Input(shape=[1], name=\"air_temperature_min_lag72\")\n",
    "    air_temperature_std_lag72 = Input(shape=[1], name=\"air_temperature_std_lag72\")\n",
    "    air_temperature_mean_lag72 = Input(shape=[1], name=\"air_temperature_mean_lag72\") \n",
    "    cloudCover_mean_lag72 = Input(shape=[1], name=\"cloudCover_mean_lag72\")\n",
    "    cloudCover_std_lag72 = Input(shape=[1], name=\"cloudCover_std_lag72\")\n",
    "    new_wind_direction_cos = Input(shape=[1], name=\"new_wind_direction_cos\")\n",
    "    new_wind_direction_sin = Input(shape=[1], name=\"new_wind_direction_sin\")\n",
    "   \n",
    "    #Embeddings layers\n",
    "    emb_site_id = Embedding(16, 8)(site_id)\n",
    "    emb_building_id = Embedding(1449, 50)(building_id)\n",
    "    emb_meter = Embedding(4, 2)(meter)\n",
    "    emb_primary_use = Embedding(16, 8)(primary_use)\n",
    "#     emb_hour_cos = Embedding(24, 12)(hour_cos)\n",
    "#     emb_hour_sin = Embedding(24, 12)(hour_sin)\n",
    "    emb_hour = Embedding(24, 12)(hour)\n",
    "#     emb_weekday_cos = Embedding(7, 3)(weekday_cos) \n",
    "#     emb_weekday_sin = Embedding(7, 3)(weekday_sin) \n",
    "    emb_weekday = Embedding(7, 3)(weekday)\n",
    "\n",
    "    concat_emb = concatenate([\n",
    "           Flatten() (emb_site_id)\n",
    "         , Flatten() (emb_building_id)\n",
    "         , Flatten() (emb_meter)\n",
    "         , Flatten() (emb_primary_use)\n",
    "         , Flatten() (emb_hour) \n",
    "#          , Flatten() (emb_hour_sin)\n",
    "         , Flatten() (emb_weekday)\n",
    "#          , Flatten() (emb_weekday_cos)\n",
    "#          , Flatten() (emb_weekday_sin)\n",
    "    ])\n",
    "\n",
    "    \n",
    "    categ = Dropout(dropout1)(Dense(dense_dim_1,activation='relu') (concat_emb))\n",
    "    categ = BatchNormalization()(categ)\n",
    "    categ = Dropout(dropout2)(Dense(dense_dim_2,activation='relu') (categ))\n",
    "    \n",
    "    #main layer\n",
    "    main_l = concatenate([\n",
    "          categ,\n",
    "          square_feet, floor_count,\n",
    "             new_floor_count, is_holiday, is_day_saving,\n",
    "            year_cos, year_sin, hour_cos, hour_sin, weekday_cos, weekday_sin, air_temperature,\n",
    "            age, dew_temperature, sea_level_pressure, new_sea_level_pressure, new_dew_temperature,\n",
    "             new_wind_speed, new_air_temperature, humidity, latitude, irradiance, feels_like,\n",
    "            new_feels_like, radiation, air_temperature_mean_lag72,\n",
    "             air_temperature_max_lag72, air_temperature_min_lag72,\n",
    "            air_temperature_std_lag72, cloudCover_mean_lag72,\n",
    "            cloudCover_std_lag72,new_wind_direction_cos,\n",
    "             new_wind_direction_sin\n",
    "    ])\n",
    "      \n",
    "    main_l = Dropout(dropout3)(Dense(dense_dim_3,activation='relu') (main_l))\n",
    "    main_l = BatchNormalization()(main_l)\n",
    "    main_l = Dropout(dropout4)(Dense(dense_dim_4,activation='relu') (main_l))\n",
    "    \n",
    "    #output\n",
    "    output = Dense(1) (main_l)\n",
    "\n",
    "    model = Model([building_id, meter, site_id, primary_use, square_feet, floor_count,\n",
    "             new_floor_count, is_holiday, weekday_cos, weekday_sin,\n",
    "            weekday, hour_cos, hour_sin, hour, year_cos, year_sin, is_day_saving, air_temperature,\n",
    "            age, dew_temperature, sea_level_pressure, new_sea_level_pressure, new_dew_temperature,\n",
    "             new_wind_speed, new_air_temperature, humidity, latitude, irradiance, feels_like,\n",
    "            new_feels_like, radiation, air_temperature_mean_lag72,\n",
    "             air_temperature_max_lag72, air_temperature_min_lag72,\n",
    "            air_temperature_std_lag72, cloudCover_mean_lag72,\n",
    "            cloudCover_std_lag72,new_wind_direction_cos,\n",
    "             new_wind_direction_sin], output)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr=lr),\n",
    "                  loss= mse_loss,\n",
    "                  metrics=[root_mean_squared_error])\n",
    "    return model\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keras_data(df, num_cols, cat_cols):\n",
    "    cols = num_cols + cat_cols\n",
    "    X = {col: np.array(df[col]) for col in cols}\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(keras_model, X_t, y_train, batch_size, epochs, X_v, y_valid, fold, patience=6):\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(\"model_\" + str(fold) + \".hdf5\",\n",
    "                                       save_best_only=True, verbose=1, monitor='val_root_mean_squared_error', mode='min')\n",
    "\n",
    "    hist = keras_model.fit(X_t, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                            validation_data=(X_v, y_valid), verbose=1,\n",
    "                            callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "    keras_model = load_model(\"model_\" + str(fold) + \".hdf5\", custom_objects={'root_mean_squared_error': root_mean_squared_error})\n",
    "    \n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "WARNING:tensorflow:From /Users/pgut682g/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/pgut682g/Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/pgut682g/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2801774 samples, validate on 703477 samples\n",
      "Epoch 1/100\n",
      "2801774/2801774 [==============================] - 156s 56us/step - loss: 3.5164 - root_mean_squared_error: 1.7355 - val_loss: 1.4942 - val_root_mean_squared_error: 0.7888\n",
      "\n",
      "Epoch 00001: val_root_mean_squared_error improved from inf to 0.78876, saving model to model_0.hdf5\n",
      "Epoch 2/100\n",
      "2801774/2801774 [==============================] - 145s 52us/step - loss: 1.5836 - root_mean_squared_error: 1.2570 - val_loss: 1.4542 - val_root_mean_squared_error: 0.7834\n",
      "\n",
      "Epoch 00002: val_root_mean_squared_error improved from 0.78876 to 0.78340, saving model to model_0.hdf5\n",
      "Epoch 3/100\n",
      "2801774/2801774 [==============================] - 137s 49us/step - loss: 1.4196 - root_mean_squared_error: 1.1901 - val_loss: 1.3513 - val_root_mean_squared_error: 0.7628\n",
      "\n",
      "Epoch 00003: val_root_mean_squared_error improved from 0.78340 to 0.76285, saving model to model_0.hdf5\n",
      "Epoch 4/100\n",
      "2801774/2801774 [==============================] - 133s 48us/step - loss: 1.3361 - root_mean_squared_error: 1.1544 - val_loss: 1.1580 - val_root_mean_squared_error: 0.7110\n",
      "\n",
      "Epoch 00004: val_root_mean_squared_error improved from 0.76285 to 0.71095, saving model to model_0.hdf5\n",
      "Epoch 5/100\n",
      "2801774/2801774 [==============================] - 157s 56us/step - loss: 1.2399 - root_mean_squared_error: 1.1121 - val_loss: 1.1536 - val_root_mean_squared_error: 0.7016\n",
      "\n",
      "Epoch 00005: val_root_mean_squared_error improved from 0.71095 to 0.70161, saving model to model_0.hdf5\n",
      "Epoch 6/100\n",
      "2801774/2801774 [==============================] - 152s 54us/step - loss: 1.1766 - root_mean_squared_error: 1.0833 - val_loss: 1.0103 - val_root_mean_squared_error: 0.6715\n",
      "\n",
      "Epoch 00006: val_root_mean_squared_error improved from 0.70161 to 0.67154, saving model to model_0.hdf5\n",
      "Epoch 7/100\n",
      "2801774/2801774 [==============================] - 146s 52us/step - loss: 1.1307 - root_mean_squared_error: 1.0619 - val_loss: 1.2590 - val_root_mean_squared_error: 0.7064\n",
      "\n",
      "Epoch 00007: val_root_mean_squared_error did not improve from 0.67154\n",
      "Epoch 8/100\n",
      "2801774/2801774 [==============================] - 2715s 969us/step - loss: 1.0862 - root_mean_squared_error: 1.0408 - val_loss: 0.9625 - val_root_mean_squared_error: 0.6662\n",
      "\n",
      "Epoch 00008: val_root_mean_squared_error improved from 0.67154 to 0.66621, saving model to model_0.hdf5\n",
      "Epoch 9/100\n",
      "2801774/2801774 [==============================] - 143s 51us/step - loss: 1.0529 - root_mean_squared_error: 1.0246 - val_loss: 1.2334 - val_root_mean_squared_error: 0.6897\n",
      "\n",
      "Epoch 00009: val_root_mean_squared_error did not improve from 0.66621\n",
      "Epoch 10/100\n",
      "2801774/2801774 [==============================] - 138s 49us/step - loss: 1.0191 - root_mean_squared_error: 1.0080 - val_loss: 1.0527 - val_root_mean_squared_error: 0.6618\n",
      "\n",
      "Epoch 00010: val_root_mean_squared_error improved from 0.66621 to 0.66185, saving model to model_0.hdf5\n",
      "Epoch 11/100\n",
      "2801774/2801774 [==============================] - 129s 46us/step - loss: 0.9851 - root_mean_squared_error: 0.9911 - val_loss: 0.9887 - val_root_mean_squared_error: 0.6486\n",
      "\n",
      "Epoch 00011: val_root_mean_squared_error improved from 0.66185 to 0.64860, saving model to model_0.hdf5\n",
      "Epoch 12/100\n",
      "2801774/2801774 [==============================] - 130s 46us/step - loss: 0.9700 - root_mean_squared_error: 0.9834 - val_loss: 0.9381 - val_root_mean_squared_error: 0.6459\n",
      "\n",
      "Epoch 00012: val_root_mean_squared_error improved from 0.64860 to 0.64587, saving model to model_0.hdf5\n",
      "Epoch 13/100\n",
      "2801774/2801774 [==============================] - 142s 51us/step - loss: 0.9547 - root_mean_squared_error: 0.9756 - val_loss: 1.0092 - val_root_mean_squared_error: 0.6440\n",
      "\n",
      "Epoch 00013: val_root_mean_squared_error improved from 0.64587 to 0.64403, saving model to model_0.hdf5\n",
      "Epoch 14/100\n",
      "2801774/2801774 [==============================] - 135s 48us/step - loss: 0.9289 - root_mean_squared_error: 0.9623 - val_loss: 0.9685 - val_root_mean_squared_error: 0.6392\n",
      "\n",
      "Epoch 00014: val_root_mean_squared_error improved from 0.64403 to 0.63916, saving model to model_0.hdf5\n",
      "Epoch 15/100\n",
      "2801774/2801774 [==============================] - 137s 49us/step - loss: 0.9098 - root_mean_squared_error: 0.9522 - val_loss: 0.8703 - val_root_mean_squared_error: 0.6250\n",
      "\n",
      "Epoch 00015: val_root_mean_squared_error improved from 0.63916 to 0.62500, saving model to model_0.hdf5\n",
      "Epoch 16/100\n",
      "2801774/2801774 [==============================] - 134s 48us/step - loss: 0.8845 - root_mean_squared_error: 0.9390 - val_loss: 0.8555 - val_root_mean_squared_error: 0.6133\n",
      "\n",
      "Epoch 00016: val_root_mean_squared_error improved from 0.62500 to 0.61327, saving model to model_0.hdf5\n",
      "Epoch 17/100\n",
      "2801774/2801774 [==============================] - 136s 49us/step - loss: 0.8751 - root_mean_squared_error: 0.9338 - val_loss: 0.9472 - val_root_mean_squared_error: 0.6265\n",
      "\n",
      "Epoch 00017: val_root_mean_squared_error did not improve from 0.61327\n",
      "Epoch 18/100\n",
      "2801774/2801774 [==============================] - 137s 49us/step - loss: 0.8635 - root_mean_squared_error: 0.9277 - val_loss: 0.8745 - val_root_mean_squared_error: 0.6129\n",
      "\n",
      "Epoch 00018: val_root_mean_squared_error improved from 0.61327 to 0.61293, saving model to model_0.hdf5\n",
      "Epoch 19/100\n",
      "2801774/2801774 [==============================] - 137s 49us/step - loss: 0.8559 - root_mean_squared_error: 0.9236 - val_loss: 0.7970 - val_root_mean_squared_error: 0.5990\n",
      "\n",
      "Epoch 00019: val_root_mean_squared_error improved from 0.61293 to 0.59904, saving model to model_0.hdf5\n",
      "Epoch 20/100\n",
      "2801774/2801774 [==============================] - 131s 47us/step - loss: 0.8484 - root_mean_squared_error: 0.9195 - val_loss: 0.8830 - val_root_mean_squared_error: 0.6370\n",
      "\n",
      "Epoch 00020: val_root_mean_squared_error did not improve from 0.59904\n",
      "Epoch 21/100\n",
      "2801774/2801774 [==============================] - 130s 46us/step - loss: 0.8446 - root_mean_squared_error: 0.9176 - val_loss: 0.8053 - val_root_mean_squared_error: 0.6022\n",
      "\n",
      "Epoch 00021: val_root_mean_squared_error did not improve from 0.59904\n",
      "Epoch 22/100\n",
      "2801774/2801774 [==============================] - 142s 51us/step - loss: 0.8354 - root_mean_squared_error: 0.9124 - val_loss: 0.8582 - val_root_mean_squared_error: 0.6100\n",
      "\n",
      "Epoch 00022: val_root_mean_squared_error did not improve from 0.59904\n",
      "Epoch 23/100\n",
      "2801774/2801774 [==============================] - 136s 49us/step - loss: 0.8300 - root_mean_squared_error: 0.9094 - val_loss: 0.7747 - val_root_mean_squared_error: 0.5817\n",
      "\n",
      "Epoch 00023: val_root_mean_squared_error improved from 0.59904 to 0.58173, saving model to model_0.hdf5\n",
      "Epoch 24/100\n",
      "2801774/2801774 [==============================] - 136s 49us/step - loss: 0.8298 - root_mean_squared_error: 0.9083 - val_loss: 0.8196 - val_root_mean_squared_error: 0.5986\n",
      "\n",
      "Epoch 00024: val_root_mean_squared_error did not improve from 0.58173\n",
      "Epoch 25/100\n",
      "2801774/2801774 [==============================] - 136s 49us/step - loss: 0.8221 - root_mean_squared_error: 0.9051 - val_loss: 0.8116 - val_root_mean_squared_error: 0.5912\n",
      "\n",
      "Epoch 00025: val_root_mean_squared_error did not improve from 0.58173\n",
      "Epoch 26/100\n",
      "2801774/2801774 [==============================] - 137s 49us/step - loss: 0.8180 - root_mean_squared_error: 0.9028 - val_loss: 0.8698 - val_root_mean_squared_error: 0.6112\n",
      "\n",
      "Epoch 00026: val_root_mean_squared_error did not improve from 0.58173\n",
      "Epoch 27/100\n",
      "2801774/2801774 [==============================] - 134s 48us/step - loss: 0.8119 - root_mean_squared_error: 0.8994 - val_loss: 0.7733 - val_root_mean_squared_error: 0.6168\n",
      "\n",
      "Epoch 00027: val_root_mean_squared_error did not improve from 0.58173\n",
      "Epoch 28/100\n",
      "2801774/2801774 [==============================] - 138s 49us/step - loss: 0.8122 - root_mean_squared_error: 0.8996 - val_loss: 0.8920 - val_root_mean_squared_error: 0.6245\n",
      "\n",
      "Epoch 00028: val_root_mean_squared_error did not improve from 0.58173\n",
      "Epoch 29/100\n",
      "2801774/2801774 [==============================] - 134s 48us/step - loss: 0.8458 - root_mean_squared_error: 0.9181 - val_loss: 0.8205 - val_root_mean_squared_error: 0.5881\n",
      "\n",
      "Epoch 00029: val_root_mean_squared_error did not improve from 0.58173\n",
      "Epoch 30/100\n",
      "2801774/2801774 [==============================] - 134s 48us/step - loss: 0.8179 - root_mean_squared_error: 0.9028 - val_loss: 0.8327 - val_root_mean_squared_error: 0.6000\n",
      "\n",
      "Epoch 00030: val_root_mean_squared_error did not improve from 0.58173\n",
      "Epoch 31/100\n",
      "2801774/2801774 [==============================] - 134s 48us/step - loss: 0.8080 - root_mean_squared_error: 0.8972 - val_loss: 0.9025 - val_root_mean_squared_error: 0.6161\n",
      "\n",
      "Epoch 00031: val_root_mean_squared_error did not improve from 0.58173\n",
      "Epoch 32/100\n",
      "2801774/2801774 [==============================] - 134s 48us/step - loss: 0.7990 - root_mean_squared_error: 0.8922 - val_loss: 0.8702 - val_root_mean_squared_error: 0.6146\n",
      "\n",
      "Epoch 00032: val_root_mean_squared_error did not improve from 0.58173\n",
      "Epoch 33/100\n",
      "2801774/2801774 [==============================] - 134s 48us/step - loss: 0.7871 - root_mean_squared_error: 0.8855 - val_loss: 0.7708 - val_root_mean_squared_error: 0.6025\n",
      "\n",
      "Epoch 00033: val_root_mean_squared_error did not improve from 0.58173\n",
      "Epoch 34/100\n",
      "2801774/2801774 [==============================] - 135s 48us/step - loss: 0.7735 - root_mean_squared_error: 0.8778 - val_loss: 0.7785 - val_root_mean_squared_error: 0.5891\n",
      "\n",
      "Epoch 00034: val_root_mean_squared_error did not improve from 0.58173\n",
      "Epoch 35/100\n",
      "2801774/2801774 [==============================] - 135s 48us/step - loss: 0.7681 - root_mean_squared_error: 0.8748 - val_loss: 0.8616 - val_root_mean_squared_error: 0.5996\n",
      "\n",
      "Epoch 00035: val_root_mean_squared_error did not improve from 0.58173\n",
      "Epoch 36/100\n",
      "2801774/2801774 [==============================] - 135s 48us/step - loss: 0.7635 - root_mean_squared_error: 0.8720 - val_loss: 0.7606 - val_root_mean_squared_error: 0.5895\n",
      "\n",
      "Epoch 00036: val_root_mean_squared_error did not improve from 0.58173\n",
      "Epoch 37/100\n",
      "2801774/2801774 [==============================] - 135s 48us/step - loss: 0.7598 - root_mean_squared_error: 0.8701 - val_loss: 0.7121 - val_root_mean_squared_error: 0.5626\n",
      "\n",
      "Epoch 00037: val_root_mean_squared_error improved from 0.58173 to 0.56257, saving model to model_0.hdf5\n",
      "Epoch 38/100\n",
      "2801774/2801774 [==============================] - 135s 48us/step - loss: 0.7575 - root_mean_squared_error: 0.8688 - val_loss: 0.7418 - val_root_mean_squared_error: 0.5776\n",
      "\n",
      "Epoch 00038: val_root_mean_squared_error did not improve from 0.56257\n",
      "Epoch 39/100\n",
      "2801774/2801774 [==============================] - 138s 49us/step - loss: 0.7537 - root_mean_squared_error: 0.8665 - val_loss: 0.7840 - val_root_mean_squared_error: 0.5899\n",
      "\n",
      "Epoch 00039: val_root_mean_squared_error did not improve from 0.56257\n",
      "Epoch 40/100\n",
      "2801774/2801774 [==============================] - 137s 49us/step - loss: 0.7509 - root_mean_squared_error: 0.8649 - val_loss: 0.7414 - val_root_mean_squared_error: 0.5781\n",
      "\n",
      "Epoch 00040: val_root_mean_squared_error did not improve from 0.56257\n",
      "Epoch 41/100\n",
      "2801774/2801774 [==============================] - 136s 49us/step - loss: 0.7495 - root_mean_squared_error: 0.8642 - val_loss: 0.8083 - val_root_mean_squared_error: 0.5906\n",
      "\n",
      "Epoch 00041: val_root_mean_squared_error did not improve from 0.56257\n",
      "Epoch 42/100\n",
      "2801774/2801774 [==============================] - 136s 49us/step - loss: 0.7486 - root_mean_squared_error: 0.8636 - val_loss: 0.7529 - val_root_mean_squared_error: 0.5723\n",
      "\n",
      "Epoch 00042: val_root_mean_squared_error did not improve from 0.56257\n",
      "Epoch 43/100\n",
      "2801774/2801774 [==============================] - 143s 51us/step - loss: 0.7463 - root_mean_squared_error: 0.8622 - val_loss: 0.7225 - val_root_mean_squared_error: 0.5841\n",
      "\n",
      "Epoch 00043: val_root_mean_squared_error did not improve from 0.56257\n",
      "Epoch 44/100\n",
      "2801774/2801774 [==============================] - 142s 51us/step - loss: 0.7439 - root_mean_squared_error: 0.8609 - val_loss: 0.7680 - val_root_mean_squared_error: 0.5792\n",
      "\n",
      "Epoch 00044: val_root_mean_squared_error did not improve from 0.56257\n",
      "Epoch 45/100\n",
      "2801774/2801774 [==============================] - 138s 49us/step - loss: 0.7413 - root_mean_squared_error: 0.8593 - val_loss: 0.8400 - val_root_mean_squared_error: 0.6025\n",
      "\n",
      "Epoch 00045: val_root_mean_squared_error did not improve from 0.56257\n",
      "Epoch 46/100\n",
      "2801774/2801774 [==============================] - 139s 50us/step - loss: 0.7386 - root_mean_squared_error: 0.8578 - val_loss: 0.7560 - val_root_mean_squared_error: 0.5951\n",
      "\n",
      "Epoch 00046: val_root_mean_squared_error did not improve from 0.56257\n",
      "Epoch 47/100\n",
      "2801774/2801774 [==============================] - 137s 49us/step - loss: 0.7385 - root_mean_squared_error: 0.8578 - val_loss: 0.7287 - val_root_mean_squared_error: 0.5715\n",
      "\n",
      "Epoch 00047: val_root_mean_squared_error did not improve from 0.56257\n",
      "Epoch 00047: early stopping\n",
      "**************************************************\n",
      "Fold: 1\n",
      "Train on 2802997 samples, validate on 702254 samples\n",
      "Epoch 1/100\n",
      "2802997/2802997 [==============================] - 143s 51us/step - loss: 3.1778 - root_mean_squared_error: 1.6557 - val_loss: 1.3741 - val_root_mean_squared_error: 0.7798\n",
      "\n",
      "Epoch 00001: val_root_mean_squared_error improved from inf to 0.77977, saving model to model_1.hdf5\n",
      "Epoch 2/100\n",
      "2802997/2802997 [==============================] - 143s 51us/step - loss: 1.5364 - root_mean_squared_error: 1.2381 - val_loss: 1.2562 - val_root_mean_squared_error: 0.7572\n",
      "\n",
      "Epoch 00002: val_root_mean_squared_error improved from 0.77977 to 0.75724, saving model to model_1.hdf5\n",
      "Epoch 3/100\n",
      "2802997/2802997 [==============================] - 144s 51us/step - loss: 1.3286 - root_mean_squared_error: 1.1511 - val_loss: 1.0455 - val_root_mean_squared_error: 0.7232\n",
      "\n",
      "Epoch 00003: val_root_mean_squared_error improved from 0.75724 to 0.72324, saving model to model_1.hdf5\n",
      "Epoch 4/100\n",
      "2802997/2802997 [==============================] - 133s 47us/step - loss: 1.1551 - root_mean_squared_error: 1.0732 - val_loss: 0.9914 - val_root_mean_squared_error: 0.6814\n",
      "\n",
      "Epoch 00004: val_root_mean_squared_error improved from 0.72324 to 0.68138, saving model to model_1.hdf5\n",
      "Epoch 5/100\n",
      "2802997/2802997 [==============================] - 156s 56us/step - loss: 1.0655 - root_mean_squared_error: 1.0307 - val_loss: 0.9112 - val_root_mean_squared_error: 0.6661\n",
      "\n",
      "Epoch 00005: val_root_mean_squared_error improved from 0.68138 to 0.66607, saving model to model_1.hdf5\n",
      "Epoch 6/100\n",
      "2802997/2802997 [==============================] - 191s 68us/step - loss: 1.0217 - root_mean_squared_error: 1.0093 - val_loss: 0.8556 - val_root_mean_squared_error: 0.6456\n",
      "\n",
      "Epoch 00006: val_root_mean_squared_error improved from 0.66607 to 0.64555, saving model to model_1.hdf5\n",
      "Epoch 7/100\n",
      "2802997/2802997 [==============================] - 134s 48us/step - loss: 0.9755 - root_mean_squared_error: 0.9861 - val_loss: 0.8628 - val_root_mean_squared_error: 0.6411\n",
      "\n",
      "Epoch 00007: val_root_mean_squared_error improved from 0.64555 to 0.64111, saving model to model_1.hdf5\n",
      "Epoch 8/100\n",
      "2802997/2802997 [==============================] - 137s 49us/step - loss: 0.9421 - root_mean_squared_error: 0.9691 - val_loss: 0.8052 - val_root_mean_squared_error: 0.6422\n",
      "\n",
      "Epoch 00008: val_root_mean_squared_error did not improve from 0.64111\n",
      "Epoch 9/100\n",
      "2802997/2802997 [==============================] - 151s 54us/step - loss: 0.9203 - root_mean_squared_error: 0.9578 - val_loss: 0.8248 - val_root_mean_squared_error: 0.6500\n",
      "\n",
      "Epoch 00009: val_root_mean_squared_error did not improve from 0.64111\n",
      "Epoch 10/100\n",
      "2802997/2802997 [==============================] - 138s 49us/step - loss: 0.9031 - root_mean_squared_error: 0.9488 - val_loss: 0.8741 - val_root_mean_squared_error: 0.6458\n",
      "\n",
      "Epoch 00010: val_root_mean_squared_error did not improve from 0.64111\n",
      "Epoch 11/100\n",
      "2802997/2802997 [==============================] - 131s 47us/step - loss: 0.8941 - root_mean_squared_error: 0.9441 - val_loss: 0.8367 - val_root_mean_squared_error: 0.6484\n",
      "\n",
      "Epoch 00011: val_root_mean_squared_error did not improve from 0.64111\n",
      "Epoch 12/100\n",
      "2802997/2802997 [==============================] - 144s 51us/step - loss: 0.8828 - root_mean_squared_error: 0.9380 - val_loss: 0.9250 - val_root_mean_squared_error: 0.6631\n",
      "\n",
      "Epoch 00012: val_root_mean_squared_error did not improve from 0.64111\n",
      "Epoch 13/100\n",
      "2802997/2802997 [==============================] - 137s 49us/step - loss: 0.8718 - root_mean_squared_error: 0.9321 - val_loss: 0.8168 - val_root_mean_squared_error: 0.6267\n",
      "\n",
      "Epoch 00013: val_root_mean_squared_error improved from 0.64111 to 0.62672, saving model to model_1.hdf5\n",
      "Epoch 14/100\n",
      "2802997/2802997 [==============================] - 145s 52us/step - loss: 0.8641 - root_mean_squared_error: 0.9279 - val_loss: 0.8858 - val_root_mean_squared_error: 0.6549\n",
      "\n",
      "Epoch 00014: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 15/100\n",
      "2802997/2802997 [==============================] - 145s 52us/step - loss: 0.8546 - root_mean_squared_error: 0.9228 - val_loss: 0.8195 - val_root_mean_squared_error: 0.6411\n",
      "\n",
      "Epoch 00015: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 16/100\n",
      "2802997/2802997 [==============================] - 143s 51us/step - loss: 0.8487 - root_mean_squared_error: 0.9198 - val_loss: 0.8102 - val_root_mean_squared_error: 0.6467\n",
      "\n",
      "Epoch 00016: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 17/100\n",
      "2802997/2802997 [==============================] - 155s 55us/step - loss: 0.8402 - root_mean_squared_error: 0.9150 - val_loss: 0.8470 - val_root_mean_squared_error: 0.6511\n",
      "\n",
      "Epoch 00017: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 18/100\n",
      "2802997/2802997 [==============================] - 142s 51us/step - loss: 0.8326 - root_mean_squared_error: 0.9108 - val_loss: 0.7983 - val_root_mean_squared_error: 0.6423\n",
      "\n",
      "Epoch 00018: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 19/100\n",
      "2802997/2802997 [==============================] - 140s 50us/step - loss: 0.8260 - root_mean_squared_error: 0.9072 - val_loss: 0.8465 - val_root_mean_squared_error: 0.6432\n",
      "\n",
      "Epoch 00019: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 20/100\n",
      "2802997/2802997 [==============================] - 148s 53us/step - loss: 0.8207 - root_mean_squared_error: 0.9043 - val_loss: 0.7876 - val_root_mean_squared_error: 0.6367\n",
      "\n",
      "Epoch 00020: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 21/100\n",
      "2802997/2802997 [==============================] - 141s 50us/step - loss: 0.8165 - root_mean_squared_error: 0.9020 - val_loss: 0.7941 - val_root_mean_squared_error: 0.6368\n",
      "\n",
      "Epoch 00021: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 22/100\n",
      "2802997/2802997 [==============================] - 136s 49us/step - loss: 0.8118 - root_mean_squared_error: 0.8994 - val_loss: 0.8661 - val_root_mean_squared_error: 0.6451\n",
      "\n",
      "Epoch 00022: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 23/100\n",
      "2802997/2802997 [==============================] - 136s 48us/step - loss: 0.8090 - root_mean_squared_error: 0.8979 - val_loss: 0.8384 - val_root_mean_squared_error: 0.6443\n",
      "\n",
      "Epoch 00023: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 24/100\n",
      "2802997/2802997 [==============================] - 137s 49us/step - loss: 0.8046 - root_mean_squared_error: 0.8954 - val_loss: 0.8302 - val_root_mean_squared_error: 0.6446\n",
      "\n",
      "Epoch 00024: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 25/100\n",
      "2802997/2802997 [==============================] - 136s 49us/step - loss: 0.8035 - root_mean_squared_error: 0.8947 - val_loss: 0.7972 - val_root_mean_squared_error: 0.6316\n",
      "\n",
      "Epoch 00025: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 26/100\n",
      "2802997/2802997 [==============================] - 137s 49us/step - loss: 0.7978 - root_mean_squared_error: 0.8916 - val_loss: 0.7964 - val_root_mean_squared_error: 0.6296\n",
      "\n",
      "Epoch 00026: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 27/100\n",
      "2802997/2802997 [==============================] - 137s 49us/step - loss: 0.7959 - root_mean_squared_error: 0.8905 - val_loss: 0.8019 - val_root_mean_squared_error: 0.6313\n",
      "\n",
      "Epoch 00027: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 28/100\n",
      "2802997/2802997 [==============================] - 137s 49us/step - loss: 0.7916 - root_mean_squared_error: 0.8881 - val_loss: 0.8441 - val_root_mean_squared_error: 0.6556\n",
      "\n",
      "Epoch 00028: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 29/100\n",
      "2802997/2802997 [==============================] - 137s 49us/step - loss: 0.7881 - root_mean_squared_error: 0.8861 - val_loss: 0.7992 - val_root_mean_squared_error: 0.6420\n",
      "\n",
      "Epoch 00029: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 30/100\n",
      "2802997/2802997 [==============================] - 136s 49us/step - loss: 0.7859 - root_mean_squared_error: 0.8849 - val_loss: 0.8383 - val_root_mean_squared_error: 0.6470\n",
      "\n",
      "Epoch 00030: val_root_mean_squared_error did not improve from 0.62672\n",
      "Epoch 00030: early stopping\n",
      "**************************************************\n",
      "Fold: 2\n",
      "Train on 2824915 samples, validate on 680336 samples\n",
      "Epoch 1/100\n",
      "2824915/2824915 [==============================] - 137s 48us/step - loss: 2.6395 - root_mean_squared_error: 1.5679 - val_loss: 1.1046 - val_root_mean_squared_error: 0.7632\n",
      "\n",
      "Epoch 00001: val_root_mean_squared_error improved from inf to 0.76324, saving model to model_2.hdf5\n",
      "Epoch 2/100\n",
      "2824915/2824915 [==============================] - 131s 46us/step - loss: 1.5454 - root_mean_squared_error: 1.2418 - val_loss: 0.9960 - val_root_mean_squared_error: 0.6959\n",
      "\n",
      "Epoch 00002: val_root_mean_squared_error improved from 0.76324 to 0.69595, saving model to model_2.hdf5\n",
      "Epoch 3/100\n",
      "2824915/2824915 [==============================] - 130s 46us/step - loss: 1.3637 - root_mean_squared_error: 1.1664 - val_loss: 0.8570 - val_root_mean_squared_error: 0.6754\n",
      "\n",
      "Epoch 00003: val_root_mean_squared_error improved from 0.69595 to 0.67539, saving model to model_2.hdf5\n",
      "Epoch 4/100\n",
      "2824915/2824915 [==============================] - 131s 46us/step - loss: 1.2386 - root_mean_squared_error: 1.1116 - val_loss: 0.8591 - val_root_mean_squared_error: 0.6827\n",
      "\n",
      "Epoch 00004: val_root_mean_squared_error did not improve from 0.67539\n",
      "Epoch 5/100\n",
      "2824915/2824915 [==============================] - 132s 47us/step - loss: 1.1589 - root_mean_squared_error: 1.0752 - val_loss: 0.7431 - val_root_mean_squared_error: 0.6348\n",
      "\n",
      "Epoch 00005: val_root_mean_squared_error improved from 0.67539 to 0.63476, saving model to model_2.hdf5\n",
      "Epoch 6/100\n",
      "2824915/2824915 [==============================] - 131s 46us/step - loss: 1.0901 - root_mean_squared_error: 1.0427 - val_loss: 0.8172 - val_root_mean_squared_error: 0.7017\n",
      "\n",
      "Epoch 00006: val_root_mean_squared_error did not improve from 0.63476\n",
      "Epoch 7/100\n",
      "2824915/2824915 [==============================] - 134s 47us/step - loss: 1.0340 - root_mean_squared_error: 1.0155 - val_loss: 0.7243 - val_root_mean_squared_error: 0.6340\n",
      "\n",
      "Epoch 00007: val_root_mean_squared_error improved from 0.63476 to 0.63400, saving model to model_2.hdf5\n",
      "Epoch 8/100\n",
      "2824915/2824915 [==============================] - 142s 50us/step - loss: 1.0025 - root_mean_squared_error: 0.9999 - val_loss: 0.6974 - val_root_mean_squared_error: 0.6169\n",
      "\n",
      "Epoch 00008: val_root_mean_squared_error improved from 0.63400 to 0.61690, saving model to model_2.hdf5\n",
      "Epoch 9/100\n",
      "2824915/2824915 [==============================] - 153s 54us/step - loss: 0.9842 - root_mean_squared_error: 0.9907 - val_loss: 0.6981 - val_root_mean_squared_error: 0.6297\n",
      "\n",
      "Epoch 00009: val_root_mean_squared_error did not improve from 0.61690\n",
      "Epoch 10/100\n",
      "2824915/2824915 [==============================] - 163s 58us/step - loss: 0.9683 - root_mean_squared_error: 0.9826 - val_loss: 0.7189 - val_root_mean_squared_error: 0.6282\n",
      "\n",
      "Epoch 00010: val_root_mean_squared_error did not improve from 0.61690\n",
      "Epoch 11/100\n",
      "2824915/2824915 [==============================] - 147s 52us/step - loss: 0.9556 - root_mean_squared_error: 0.9761 - val_loss: 0.6601 - val_root_mean_squared_error: 0.6022\n",
      "\n",
      "Epoch 00011: val_root_mean_squared_error improved from 0.61690 to 0.60224, saving model to model_2.hdf5\n",
      "Epoch 12/100\n",
      "2824915/2824915 [==============================] - 154s 54us/step - loss: 0.9446 - root_mean_squared_error: 0.9705 - val_loss: 0.6642 - val_root_mean_squared_error: 0.5930\n",
      "\n",
      "Epoch 00012: val_root_mean_squared_error improved from 0.60224 to 0.59296, saving model to model_2.hdf5\n",
      "Epoch 13/100\n",
      "2824915/2824915 [==============================] - 148s 53us/step - loss: 0.9373 - root_mean_squared_error: 0.9668 - val_loss: 0.6789 - val_root_mean_squared_error: 0.6143\n",
      "\n",
      "Epoch 00013: val_root_mean_squared_error did not improve from 0.59296\n",
      "Epoch 14/100\n",
      "2824915/2824915 [==============================] - 148s 52us/step - loss: 0.9328 - root_mean_squared_error: 0.9644 - val_loss: 0.6626 - val_root_mean_squared_error: 0.6193\n",
      "\n",
      "Epoch 00014: val_root_mean_squared_error did not improve from 0.59296\n",
      "Epoch 15/100\n",
      "2824915/2824915 [==============================] - 149s 53us/step - loss: 0.9258 - root_mean_squared_error: 0.9608 - val_loss: 0.6677 - val_root_mean_squared_error: 0.6141\n",
      "\n",
      "Epoch 00015: val_root_mean_squared_error did not improve from 0.59296\n",
      "Epoch 16/100\n",
      "2824915/2824915 [==============================] - 169s 60us/step - loss: 0.9198 - root_mean_squared_error: 0.9577 - val_loss: 0.6461 - val_root_mean_squared_error: 0.5910\n",
      "\n",
      "Epoch 00016: val_root_mean_squared_error improved from 0.59296 to 0.59096, saving model to model_2.hdf5\n",
      "Epoch 17/100\n",
      "2824915/2824915 [==============================] - 163s 58us/step - loss: 0.9163 - root_mean_squared_error: 0.9558 - val_loss: 0.6688 - val_root_mean_squared_error: 0.6207\n",
      "\n",
      "Epoch 00017: val_root_mean_squared_error did not improve from 0.59096\n",
      "Epoch 18/100\n",
      "2824915/2824915 [==============================] - 238s 84us/step - loss: 0.9143 - root_mean_squared_error: 0.9548 - val_loss: 0.6656 - val_root_mean_squared_error: 0.6145\n",
      "\n",
      "Epoch 00018: val_root_mean_squared_error did not improve from 0.59096\n",
      "Epoch 19/100\n",
      "2824915/2824915 [==============================] - 193s 68us/step - loss: 0.9118 - root_mean_squared_error: 0.9534 - val_loss: 0.6472 - val_root_mean_squared_error: 0.6051\n",
      "\n",
      "Epoch 00019: val_root_mean_squared_error did not improve from 0.59096\n",
      "Epoch 20/100\n",
      "2824915/2824915 [==============================] - 180s 64us/step - loss: 0.9070 - root_mean_squared_error: 0.9509 - val_loss: 0.6380 - val_root_mean_squared_error: 0.5929\n",
      "\n",
      "Epoch 00020: val_root_mean_squared_error did not improve from 0.59096\n",
      "Epoch 21/100\n",
      "2824915/2824915 [==============================] - 201s 71us/step - loss: 0.9045 - root_mean_squared_error: 0.9497 - val_loss: 0.6630 - val_root_mean_squared_error: 0.6079\n",
      "\n",
      "Epoch 00021: val_root_mean_squared_error did not improve from 0.59096\n",
      "Epoch 22/100\n",
      "2824915/2824915 [==============================] - 271s 96us/step - loss: 0.9004 - root_mean_squared_error: 0.9476 - val_loss: 0.6487 - val_root_mean_squared_error: 0.6013\n",
      "\n",
      "Epoch 00022: val_root_mean_squared_error did not improve from 0.59096\n",
      "Epoch 23/100\n",
      "2824915/2824915 [==============================] - 308s 109us/step - loss: 0.8979 - root_mean_squared_error: 0.9462 - val_loss: 0.6574 - val_root_mean_squared_error: 0.6211\n",
      "\n",
      "Epoch 00023: val_root_mean_squared_error did not improve from 0.59096\n",
      "Epoch 24/100\n",
      "2824915/2824915 [==============================] - 226s 80us/step - loss: 0.8946 - root_mean_squared_error: 0.9443 - val_loss: 0.6192 - val_root_mean_squared_error: 0.5756\n",
      "\n",
      "Epoch 00024: val_root_mean_squared_error improved from 0.59096 to 0.57557, saving model to model_2.hdf5\n",
      "Epoch 25/100\n",
      "2824915/2824915 [==============================] - 257s 91us/step - loss: 0.8884 - root_mean_squared_error: 0.9411 - val_loss: 0.6390 - val_root_mean_squared_error: 0.5974\n",
      "\n",
      "Epoch 00025: val_root_mean_squared_error did not improve from 0.57557\n",
      "Epoch 26/100\n",
      "2824915/2824915 [==============================] - 314s 111us/step - loss: 0.8849 - root_mean_squared_error: 0.9393 - val_loss: 0.6561 - val_root_mean_squared_error: 0.6002\n",
      "\n",
      "Epoch 00026: val_root_mean_squared_error did not improve from 0.57557\n",
      "Epoch 27/100\n",
      "2824915/2824915 [==============================] - 356s 126us/step - loss: 0.8783 - root_mean_squared_error: 0.9358 - val_loss: 0.6345 - val_root_mean_squared_error: 0.5880\n",
      "\n",
      "Epoch 00027: val_root_mean_squared_error did not improve from 0.57557\n",
      "Epoch 28/100\n",
      "2824915/2824915 [==============================] - 352s 125us/step - loss: 0.8748 - root_mean_squared_error: 0.9339 - val_loss: 0.6202 - val_root_mean_squared_error: 0.5855\n",
      "\n",
      "Epoch 00028: val_root_mean_squared_error did not improve from 0.57557\n",
      "Epoch 29/100\n",
      "2824915/2824915 [==============================] - 328s 116us/step - loss: 0.8675 - root_mean_squared_error: 0.9299 - val_loss: 0.6466 - val_root_mean_squared_error: 0.6020\n",
      "\n",
      "Epoch 00029: val_root_mean_squared_error did not improve from 0.57557\n",
      "Epoch 30/100\n",
      " 969728/2824915 [=========>....................] - ETA: 3:39 - loss: 0.8657 - root_mean_squared_error: 0.9292"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0338349af949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     keras_model = model(dense_dim_1=64, dense_dim_2=32, dense_dim_3=32, dense_dim_4=16,  \n\u001b[1;32m     27\u001b[0m                         dropout1=0.2, dropout2=0.1, dropout3=0.1, dropout4=0.1, lr=3e-4)\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-49a60a2e9cac>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(keras_model, X_t, y_train, batch_size, epochs, X_v, y_valid, fold, patience)\u001b[0m\n\u001b[1;32m      6\u001b[0m     hist = keras_model.fit(X_t, y_train, batch_size=batch_size, epochs=epochs,\n\u001b[1;32m      7\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                             callbacks=[early_stopping, model_checkpoint])\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'root_mean_squared_error'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot_mean_squared_error\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "batch_size = 1024   \n",
    "epochs = 100\n",
    "models = []\n",
    "\n",
    "folds = 3   \n",
    "seed = 666\n",
    "\n",
    "group = train['building_id'].astype(str) + \"_\" + (train['timestamp'].dt.month).astype(str)\n",
    "groupSplit = GroupShuffleSplit(folds, test_size=0.2, random_state=7)\n",
    "#folds = groupSplit.split(train[['radiation']], train['meter'], groups=group)\n",
    "\n",
    "# kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "# for fold_n, (train_index, valid_index) in enumerate(kf.split(train, train['building_id'])):\n",
    "for fold_n, (train_index, valid_index) in enumerate(groupSplit.split(train, target, groups=group)):\n",
    "#for train_index, valid_index in groupSplit.split(train, target, groups=group):\n",
    "    print('Fold:', fold_n)\n",
    "    X_train, X_valid = train.iloc[train_index], train.iloc[valid_index]\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "    X_t = get_keras_data(X_train, numericals, categoricals)\n",
    "    X_v = get_keras_data(X_valid, numericals, categoricals)\n",
    "    \n",
    "    keras_model = model(dense_dim_1=64, dense_dim_2=32, dense_dim_3=32, dense_dim_4=16,  \n",
    "                        dropout1=0.2, dropout2=0.1, dropout3=0.1, dropout4=0.1, lr=3e-4)\n",
    "    mod = train_model(keras_model, X_t, y_train, batch_size, epochs, X_v, y_valid, fold_n, patience=10)\n",
    "    models.append(mod) \n",
    "    print('*'* 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1042 folds 5\n",
    "- Model 0: 0.69026, 0.9391\n",
    "- Model 1: 0.57073, 0.8925\n",
    "- Model 2: 0.66545, 0.8997\n",
    "- Model 3: 0.59834, 0.9236\n",
    "- Model 4: 0.53854, 0.9353\n",
    "\n",
    "1024 folds 3\n",
    "- model 0: 0.6287, 0.8934\n",
    "- model 1: 0.57151, 0.8645\n",
    "- model 2: 0.65070, 0.8678\n",
    "\n",
    "1024 inf folds 3\n",
    "- model 0: 0.56257, 0.8701\n",
    "- model 1: 0.62672, 0.9321\n",
    "- model 2: 0.57557, 0.9443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  6,  1,  7, 11,  8,  9, 15,  2, 10,  3, 14, 13,  5, 12])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_train[\"primary_use\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pgut682g/Applications/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:564: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e431ae3fbb18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_for_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"primary_use\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_for_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"primary_use\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_for_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_for_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"utc_time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_for_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_for_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"utc_time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_for_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"year_built\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_for_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"month\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_for_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"utc_time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[0;32m---> 53\u001b[0;31m                              % str(diff))\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]"
     ]
    }
   ],
   "source": [
    "\n",
    "test_for_train[\"timestamp\"] = test_for_train[\"utc_time\"]\n",
    "test_for_train[\"age\"] = test_for_train[\"utc_time\"].dt.year - test_for_train[\"year_built\"]\n",
    "\n",
    "test_for_train[\"month\"] = test_for_train[\"utc_time\"].dt.month\n",
    "test_for_train[\"day\"] = test_for_train[\"utc_time\"].dt.day\n",
    "\n",
    "test_for_train[\"year_built\"] = test_for_train.apply(\n",
    "                                lambda row: row['new_year_built'] if np.isnan(row['year_built']) else row['new_year_built'],\n",
    "                                axis=1\n",
    "                                )\n",
    "\n",
    "test_for_train[\"floor_count\"] = test_for_train.apply(\n",
    "                                lambda row: row['new_floor_count'] if np.isnan(row['floor_count']) else row['new_floor_count'],\n",
    "                                axis=1\n",
    "                                )\n",
    "\n",
    "test_for_train[\"hour\"] = test_for_train[\"utc_time\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_for_train[feat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['age'].replace([np.inf, -np.inf], -999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_train = test_for_train.set_index(['site_id','day','month'])\n",
    "\n",
    "air_temperature_filler = test_for_train.groupby(['site_id','day','month'])['air_temperature'].mean()\n",
    "air_temperature_filler = pd.DataFrame(air_temperature_filler.fillna(method='ffill'),columns=['air_temperature'])\n",
    "test_for_train.update(air_temperature_filler,overwrite=False)\n",
    "\n",
    "cloud_coverage_filler = test_for_train.groupby(['site_id','day','month'])['cloud_coverage'].mean()\n",
    "cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=['cloud_coverage'])\n",
    "test_for_train.update(cloud_coverage_filler,overwrite=False)\n",
    "\n",
    "dew_temperature_filler = test_for_train.groupby(['site_id','day','month'])['dew_temperature'].mean()\n",
    "dew_temperature_filler = pd.DataFrame(dew_temperature_filler.fillna(method='ffill'),columns=['dew_temperature'])\n",
    "test_for_train.update(dew_temperature_filler,overwrite=False)\n",
    "\n",
    "precip_depth_1_hr_filler = test_for_train.groupby(['site_id','day','month'])['precip_depth_1_hr'].mean()\n",
    "precip_depth_1_hr_filler = pd.DataFrame(precip_depth_1_hr_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n",
    "test_for_train.update(precip_depth_1_hr_filler,overwrite=False)\n",
    "\n",
    "sea_level_pressure_filler = test_for_train.groupby(['site_id','day','month'])['sea_level_pressure'].mean()\n",
    "sea_level_pressure_filler = pd.DataFrame(sea_level_pressure_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n",
    "test_for_train.update(sea_level_pressure_filler,overwrite=False)\n",
    "\n",
    "wind_speed_filler = test_for_train.groupby(['site_id','day','month'])['wind_speed'].mean()\n",
    "wind_speed_filler = pd.DataFrame(wind_speed_filler.fillna(method='ffill'),columns=['wind_speed'])\n",
    "test_for_train.update(wind_speed_filler,overwrite=False)\n",
    "\n",
    "new_sea_level_pressure_filler = test_for_train.groupby(['site_id','day','month'])['new_sea_level_pressure'].mean()\n",
    "new_sea_level_pressure_filler = pd.DataFrame(new_sea_level_pressure_filler.fillna(method='ffill'),columns=['new_sea_level_pressure'])\n",
    "test_for_train.update(new_sea_level_pressure_filler,overwrite=False)\n",
    "\n",
    "new_dew_temperature_filler = test_for_train.groupby(['site_id','day','month'])['new_dew_temperature'].mean()\n",
    "new_dew_temperature_filler = pd.DataFrame(new_dew_temperature_filler.fillna(method='ffill'),columns=['new_dew_temperature'])\n",
    "test_for_train.update(new_dew_temperature_filler,overwrite=False)\n",
    "\n",
    "new_wind_speed_filler = test_for_train.groupby(['site_id','day','month'])['new_wind_speed'].mean()\n",
    "new_wind_speed_filler = pd.DataFrame(new_wind_speed_filler.fillna(method='ffill'),columns=['new_wind_speed'])\n",
    "test_for_train.update(new_wind_speed_filler,overwrite=False)\n",
    "\n",
    "new_cloud_coverage_filler = test_for_train.groupby(['site_id','day','month'])['new_cloud_coverage'].mean()\n",
    "new_cloud_coverage_filler = pd.DataFrame(new_cloud_coverage_filler.fillna(method='ffill'),columns=['new_cloud_coverage'])\n",
    "test_for_train.update(new_cloud_coverage_filler,overwrite=False)\n",
    "\n",
    "new_precip_depth_1_hr_filler = test_for_train.groupby(['site_id','day','month'])['new_precip_depth_1_hr'].mean()\n",
    "new_precip_depth_1_hr_filler = pd.DataFrame(new_precip_depth_1_hr_filler.fillna(method='ffill'),columns=['new_precip_depth_1_hr'])\n",
    "test_for_train.update(new_precip_depth_1_hr_filler,overwrite=False)\n",
    "\n",
    "cloudCover_max_lag72_filler = test_for_train.groupby(['site_id','day','month'])['cloudCover_max_lag72'].mean()\n",
    "cloudCover_max_lag72_filler = pd.DataFrame(cloudCover_max_lag72_filler.fillna(method='ffill'),columns=['cloudCover_max_lag72'])\n",
    "test_for_train.update(cloudCover_max_lag72_filler,overwrite=False)\n",
    "\n",
    "cloudCover_min_lag72_filler = test_for_train.groupby(['site_id','day','month'])['cloudCover_min_lag72'].mean()\n",
    "cloudCover_min_lag72_filler = pd.DataFrame(cloudCover_min_lag72_filler.fillna(method='ffill'),columns=['cloudCover_min_lag72'])\n",
    "test_for_train.update(cloudCover_min_lag72_filler,overwrite=False)\n",
    "\n",
    "cloudCover_std_lag72_filler = test_for_train.groupby(['site_id','day','month'])['cloudCover_std_lag72'].mean()\n",
    "cloudCover_std_lag72_filler = pd.DataFrame(cloudCover_std_lag72_filler.fillna(method='ffill'),columns=['cloudCover_std_lag72'])\n",
    "test_for_train.update(cloudCover_std_lag72_filler,overwrite=False)\n",
    "\n",
    "beaufort_scale_filler = test_for_train.groupby(['site_id','day','month'])['beaufort_scale'].mean()\n",
    "beaufort_scale_filler = pd.DataFrame(beaufort_scale_filler.fillna(method='ffill'),columns=['beaufort_scale'])\n",
    "test_for_train.update(beaufort_scale_filler,overwrite=False)\n",
    "\n",
    "wind_direction_cos_filler = test_for_train.groupby(['site_id','day','month'])['wind_direction_cos'].mean()\n",
    "wind_direction_cos_filler = pd.DataFrame(wind_direction_cos_filler.fillna(method='ffill'),columns=['wind_direction_cos'])\n",
    "test_for_train.update(wind_direction_cos_filler,overwrite=False)\n",
    "\n",
    "wind_direction_sin_filler = test_for_train.groupby(['site_id','day','month'])['wind_direction_sin'].mean()\n",
    "wind_direction_sin_filler = pd.DataFrame(wind_direction_sin_filler.fillna(method='ffill'),columns=['wind_direction_sin'])\n",
    "test_for_train.update(wind_direction_sin_filler,overwrite=False)\n",
    "\n",
    "new_wind_direction_cos_filler = test_for_train.groupby(['site_id','day','month'])['new_wind_direction_cos'].mean()\n",
    "new_wind_direction_cos_filler = pd.DataFrame(new_wind_direction_cos_filler.fillna(method='ffill'),columns=['new_wind_direction_cos'])\n",
    "test_for_train.update(new_wind_direction_cos_filler,overwrite=False)\n",
    "\n",
    "new_wind_direction_sin_filler = test_for_train.groupby(['site_id','day','month'])['new_wind_direction_sin'].mean()\n",
    "new_wind_direction_sin_filler = pd.DataFrame(new_wind_direction_sin_filler.fillna(method='ffill'),columns=['new_wind_direction_sin'])\n",
    "test_for_train.update(new_wind_direction_sin_filler,overwrite=False)\n",
    "\n",
    "new_feels_like_filler = test_for_train.groupby(['site_id','day','month'])['new_feels_like'].mean()\n",
    "new_feels_like_filler = pd.DataFrame(new_feels_like_filler.fillna(method='ffill'),columns=['new_feels_like'])\n",
    "test_for_train.update(new_feels_like_filler,overwrite=False)\n",
    "\n",
    "new_air_temperature_filler = test_for_train.groupby(['site_id','day','month'])['new_air_temperature'].mean()\n",
    "new_air_temperature_filler = pd.DataFrame(new_air_temperature_filler.fillna(method='ffill'),columns=['new_air_temperature'])\n",
    "test_for_train.update(new_air_temperature_filler,overwrite=False)\n",
    "\n",
    "uvIndex_filler = test_for_train.groupby(['site_id','day','month'])['uvIndex'].mean()\n",
    "uvIndex_filler = pd.DataFrame(uvIndex_filler.fillna(method='ffill'),columns=['uvIndex'])\n",
    "test_for_train.update(uvIndex_filler,overwrite=False)\n",
    "\n",
    "cloudCover_filler = test_for_train.groupby(['site_id','day','month'])['cloudCover'].mean()\n",
    "cloudCover_filler = pd.DataFrame(cloudCover_filler.fillna(method='ffill'),columns=['cloudCover'])\n",
    "test_for_train.update(cloudCover_filler,overwrite=False)\n",
    "\n",
    "humidity_filler = test_for_train.groupby(['site_id','day','month'])['humidity'].mean()\n",
    "humidity_filler = pd.DataFrame(humidity_filler.fillna(method='ffill'),columns=['humidity'])\n",
    "test_for_train.update(humidity_filler,overwrite=False)\n",
    "\n",
    "latitude_filler = test_for_train.groupby(['site_id','day','month'])['latitude'].mean()\n",
    "latitude_filler = pd.DataFrame(latitude_filler.fillna(method='ffill'),columns=['latitude'])\n",
    "test_for_train.update(latitude_filler,overwrite=False)\n",
    "\n",
    "longitude_filler = test_for_train.groupby(['site_id','day','month'])['longitude'].mean()\n",
    "longitude_filler = pd.DataFrame(longitude_filler.fillna(method='ffill'),columns=['longitude'])\n",
    "test_for_train.update(longitude_filler,overwrite=False)\n",
    "\n",
    "irradiance_filler = test_for_train.groupby(['site_id','day','month'])['irradiance'].mean()\n",
    "irradiance_filler = pd.DataFrame(irradiance_filler.fillna(method='ffill'),columns=['irradiance'])\n",
    "test_for_train.update(irradiance_filler,overwrite=False)\n",
    "\n",
    "irradiance_cloud_filler = test_for_train.groupby(['site_id','day','month'])['irradiance_cloud'].mean()\n",
    "irradiance_cloud_filler = pd.DataFrame(irradiance_cloud_filler.fillna(method='ffill'),columns=['irradiance_cloud'])\n",
    "test_for_train.update(irradiance_cloud_filler,overwrite=False)\n",
    "\n",
    "feels_like_filler = test_for_train.groupby(['site_id','day','month'])['feels_like'].mean()\n",
    "feels_like_filler = pd.DataFrame(feels_like_filler.fillna(method='ffill'),columns=['feels_like'])\n",
    "test_for_train.update(feels_like_filler,overwrite=False)\n",
    "\n",
    "altitude_filler = test_for_train.groupby(['site_id','day','month'])['altitude'].mean()\n",
    "altitude_filler = pd.DataFrame(altitude_filler.fillna(method='ffill'),columns=['altitude'])\n",
    "test_for_train.update(altitude_filler,overwrite=False)\n",
    "\n",
    "azimuth_filler = test_for_train.groupby(['site_id','day','month'])['azimuth'].mean()\n",
    "azimuth_filler = pd.DataFrame(azimuth_filler.fillna(method='ffill'),columns=['azimuth'])\n",
    "test_for_train.update(azimuth_filler,overwrite=False)\n",
    "\n",
    "radiation_filler = test_for_train.groupby(['site_id','day','month'])['radiation'].mean()\n",
    "radiation_filler = pd.DataFrame(radiation_filler.fillna(method='ffill'),columns=['radiation'])\n",
    "test_for_train.update(radiation_filler,overwrite=False)\n",
    "\n",
    "air_temperature_mean_lag72_filler = test_for_train.groupby(['site_id','day','month'])['air_temperature_mean_lag72'].mean()\n",
    "air_temperature_mean_lag72_filler = pd.DataFrame(air_temperature_mean_lag72_filler.fillna(method='ffill'),columns=['air_temperature_mean_lag72'])\n",
    "test_for_train.update(air_temperature_mean_lag72_filler,overwrite=False)\n",
    "\n",
    "air_temperature_max_lag72_filler = test_for_train.groupby(['site_id','day','month'])['air_temperature_max_lag72'].mean()\n",
    "air_temperature_max_lag72_filler = pd.DataFrame(air_temperature_max_lag72_filler.fillna(method='ffill'),columns=['air_temperature_max_lag72'])\n",
    "test_for_train.update(air_temperature_max_lag72_filler,overwrite=False)\n",
    "\n",
    "air_temperature_min_lag72_filler = test_for_train.groupby(['site_id','day','month'])['air_temperature_min_lag72'].mean()\n",
    "air_temperature_min_lag72_filler = pd.DataFrame(air_temperature_min_lag72_filler.fillna(method='ffill'),columns=['air_temperature_min_lag72'])\n",
    "test_for_train.update(air_temperature_min_lag72_filler,overwrite=False)\n",
    "\n",
    "air_temperature_std_lag72_filler = test_for_train.groupby(['site_id','day','month'])['air_temperature_std_lag72'].mean()\n",
    "air_temperature_std_lag72_filler = pd.DataFrame(air_temperature_std_lag72_filler.fillna(method='ffill'),columns=['air_temperature_std_lag72'])\n",
    "test_for_train.update(air_temperature_std_lag72_filler,overwrite=False)\n",
    "\n",
    "cloudCover_mean_lag72_filler = test_for_train.groupby(['site_id','day','month'])['cloudCover_mean_lag72'].mean()\n",
    "cloudCover_mean_lag72_filler = pd.DataFrame(cloudCover_mean_lag72_filler.fillna(method='ffill'),columns=['cloudCover_mean_lag72'])\n",
    "test_for_train.update(cloudCover_mean_lag72_filler,overwrite=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_train = test_for_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "models = []\n",
    "#mod = model(dense_dim_1=64, dense_dim_2=32, dense_dim_3=32, dense_dim_4=16, dropout1=0.2, dropout2=0.1, dropout3=0.1, dropout4=0.1, lr=3e-4)\n",
    "\n",
    "mod = load_model('model_building_id_month_1024_3_fold/model_0.hdf5',custom_objects={\"root_mean_squared_error\": root_mean_squared_error})\n",
    "models.append(mod) \n",
    "mod = load_model('model_building_id_month_1024_3_fold/model_1.hdf5',custom_objects={\"root_mean_squared_error\": root_mean_squared_error})\n",
    "models.append(mod)\n",
    "mod = load_model('model_building_id_month_1024_3_fold/model_2.hdf5',custom_objects={\"root_mean_squared_error\": root_mean_squared_error})\n",
    "models.append(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "i=0\n",
    "res = np.zeros((test.shape[0]),dtype=np.float32)\n",
    "step_size = 50000\n",
    "for j in tqdm(range(int(np.ceil(test.shape[0]/step_size)))):\n",
    "    for_prediction = get_keras_data(test.iloc[i:i+step_size], numericals, categoricals)\n",
    "    res[i:min(i+step_size,test.shape[0])] = \\\n",
    "       np.expm1(models[0].predict(for_prediction, batch_size=1024)[:,0]) \n",
    "    i+=step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[2260080] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(np.isnan(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[[2260080]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(path + '/data-vol-1/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['meter_reading'] = res\n",
    "submission.loc[submission['meter_reading']<0, 'meter_reading'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(150)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaked = feather.read_dataframe(path + '/data-vol-3/leaked_submission.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(leaked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaked = leaked.dropna()\n",
    "print(leaked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaked.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission.set_index('row_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission = submission.replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.log1p(submission.loc[leaked.index,'meter_reading'])\n",
    "real = np.log1p(leaked['meter_reading'])\n",
    "RMSLE = np.sqrt(np.mean(np.power(real-predicted,2)))\n",
    "print(RMSLE.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "submission.loc[leaked.index,'meter_reading'] = leaked['meter_reading']\n",
    "submission['meter_reading'] = submission['meter_reading'].round(4)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('nn_imputed_nn_3.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaked.index[~pd.Series(leaked.index).isin(submission.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
