{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !pip install catboost\n",
    "# !pip install lightgbm\n",
    "# !pip install feather-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import random\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import feather\n",
    "import os\n",
    "import glob\n",
    "import csv   \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImp(model, cols, num = 60):\n",
    "    feature_imp = pd.DataFrame({'Value':model.feature_importance(),'Feature':cols})\n",
    "    plt.figure(figsize=(40, 20))\n",
    "    sns.set(font_scale = 3)\n",
    "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", \n",
    "                                                        ascending=False)[0:num], color='C0')\n",
    "    plt.title('LightGBM Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = feather.read_dataframe('../../data-vol-2/Prepared_data/train_prepared.feather')\n",
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "train['meter_reading'] = np.log1p(train['meter_reading'])\n",
    "\n",
    "train.drop(columns=['utc','utc_time','altitude','azimuth'], inplace=True)\n",
    "\n",
    "gc.collect()\n",
    "train['irradiance_cloud'] = train['irradiance']*(1-train['cloudCover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['sea_level_pressure',\n",
    "    'dew_temperature',\n",
    "    'wind_speed',\n",
    "    'cloud_coverage',\n",
    "    'wind_direction',\n",
    "    'precip_depth_1_hr',\n",
    "    'air_temperature']:\n",
    "    train[f] = np.where(train[f].isna(),train[f],train[f'new_{f}'])\n",
    "    train = train.drop(columns=[f'new_{f}'])\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train['site_id'].astype(str) + \"_\" + (train['timestamp'].dt.month).astype(str)\n",
    "\n",
    "groupSplit = GroupShuffleSplit(5, test_size=0.2, random_state=7)\n",
    "folds = groupSplit.split(train[['radiation']],\n",
    "                         train['meter_reading'],\n",
    "                         groups=group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['building_id', \n",
    "            'meter', \n",
    "            'site_id', \n",
    "            'primary_use',\n",
    "            'square_feet', \n",
    "            'year_built', \n",
    "            'new_floor_count',\n",
    "            'is_holiday', \n",
    "            'weekday_cos',\n",
    "            'weekday_sin', \n",
    "            'weekday', \n",
    "            'hour_cos', \n",
    "            'hour_sin', \n",
    "            'year_cos',\n",
    "            'year_sin', \n",
    "            'night_time', \n",
    "            'is_day_saving',\n",
    "            'air_temperature',\n",
    "            'cloud_coverage', \n",
    "            'dew_temperature',\n",
    "            'precip_depth_1_hr', \n",
    "            'sea_level_pressure', \n",
    "            'wind_speed', \n",
    "            'cloudCover', \n",
    "            'humidity', \n",
    "            'irradiance', \n",
    "            'feels_like', \n",
    "            'irradiance_cloud'\n",
    "#             'floor_count', \n",
    "#             'new_year_built', \n",
    "#             'square_feet_log', \n",
    "#             'new_sea_level_pressure',\n",
    "#             'new_dew_temperature',\n",
    "#             'new_wind_speed',\n",
    "#             'new_cloud_coverage',            \n",
    "#             'new_precip_depth_1_hr',\n",
    "#             'new_air_temperature',\n",
    "#             'new_wind_direction',\n",
    "#             'radiation',\n",
    "#             'wind_direction',            \n",
    "#             'latitude',\n",
    "#             'longitude',\n",
    "#             'morning',\n",
    "#             'afternoon',\n",
    "#             'evening',\n",
    "           ]\n",
    "\n",
    "target = 'meter_reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['primary_use','is_day_saving','is_holiday']:\n",
    "    train[f] = train[f].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 2\n",
    "lgb_params = {\n",
    "              'objective':'regression',\n",
    "              'boosting_type':'gbdt',\n",
    "              'metric':'rmse',\n",
    "              'n_jobs':-1,\n",
    "              'learning_rate':0.05,\n",
    "              'num_leaves': 2**8,\n",
    "              'max_depth':-1,\n",
    "              'tree_learner':'serial',\n",
    "              'colsample_bytree': 0.9,\n",
    "              'subsample_freq':1,\n",
    "              'subsample':0.5,\n",
    "              'n_estimators':2000,\n",
    "              'max_bin':255,\n",
    "              'verbose':2,\n",
    "              'seed': seed,\n",
    "              'early_stopping_rounds':100 \n",
    "            } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lgbm'\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(folds):  \n",
    "    print(f\"\\n\\n\\n ===== Fold numer {i} =====\")\n",
    "    tr_data = lgb.Dataset(train.loc[train_index][features], label=train.loc[train_index][target])\n",
    "    vl_data = lgb.Dataset(train.loc[test_index][features], label=train.loc[test_index][target])\n",
    "    gc.collect()\n",
    "    estimator = lgb.train(\n",
    "                lgb_params,\n",
    "                tr_data,\n",
    "                valid_sets = [tr_data,vl_data],\n",
    "                verbose_eval = 50)\n",
    "    model_filename = 'models/' + model_name + '_v_' + str(version) + '__fold_' + str(i)  + '.bin'\n",
    "    pickle.dump(estimator, open(model_filename, 'wb'))\n",
    "\n",
    "    models.append(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame({'Feature':tr_data.feature_name})\n",
    "\n",
    "for i in range(1,len(models)):\n",
    "    feature_imp[f'Importance_{i}'] = models[i].feature_importance()\n",
    "\n",
    "feature_imp['mean'] = feature_imp[[col for col in feature_imp.columns if 'Importance' in col]].mean(axis=1).round(0)\n",
    "\n",
    "feature_imp = feature_imp.sort_values('mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 20))\n",
    "sns.set(font_scale = 3)\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", \n",
    "                                                    ascending=False)[0:num], color='C0')\n",
    "plt.title('LightGBM Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_performance = (sum([models[i].best_score['valid_1']['rmse'] for i in range(len(models))]))/len(models)\n",
    "print(f\"Mean performance: {round(mean_performance,3)}\")\n",
    "\n",
    "perf = [version, tr_data.feature_name, lgb_params, mean_performance]\n",
    "\n",
    "\n",
    "with open(r'./models/perf.csv', 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On leaked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = feather.read_dataframe(f\"../../data-vol-2/Prepared_data/test_prepared.feather\")\n",
    "\n",
    "test = test.set_index('row_id')\n",
    "test = test.sort_index()\n",
    "gc.collect()\n",
    "\n",
    "%%time\n",
    "leaked = feather.read_dataframe(f\"../../data-vol-2/Leaked_data/leaked_submission.feather\")\n",
    "\n",
    "test = test.loc[leaked['row_id']]\n",
    "test['meter_reading']=leaked['meter_reading']\n",
    "test['meter_reading_log'] = np.log1p(test['meter_reading'])\n",
    "\n",
    "del leaked\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = glob.glob('./models/*.bin') + glob.glob('./models/*.txt')[1:2]\n",
    "\n",
    "for m in model_names:\n",
    "    \n",
    "    step = 1000000\n",
    "    i = 0\n",
    "    test['pred'] = np.nan\n",
    "    estimator = pickle.load(open(m,'rb'))\n",
    "\n",
    "    while i < test.shape[0]:\n",
    "        print(i)\n",
    "        subset = test.loc[i:(i+step)].reset_index()[estimator.feature_name()].copy()\n",
    "        test.loc[i:(i+step),'pred'] = estimator.predict(subset)\n",
    "        i = i + step\n",
    "        gc.collect()\n",
    "        \n",
    "    error = np.sqrt(mean_squared_error(test['meter_reading_log'],test['pred']))\n",
    "    \n",
    "    with open(r'./models/perf_leaked.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([m,error])\n",
    "    \n",
    "    print(m)\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# step = 10000000\n",
    "# i = 0\n",
    "# test['pred'] = np.nan\n",
    "\n",
    "# while i < test.shape[0]:\n",
    "#     print(i)\n",
    "#     subset = test.loc[i:(i+step)].reset_index().copy()\n",
    "#     subset = pd.merge(subset, weather, how='left', left_on=['site_id','utc_time'], right_on=['site_id','timestamp'])\n",
    "#     subset = subset.sort_values('row_id')\n",
    "#     pred = estimator.predict(subset[features])\n",
    "#     test.loc[i:(i+step),'pred'] = pred\n",
    "#     i = i + step\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test[['pred']].copy()\n",
    "submission['meter_reading'] = np.exp(submission['pred'])-1\n",
    "\n",
    "submission[['meter_reading']].to_csv(f'../Prepared_data/submission_v{version}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = Pool(train.loc[train_index,features], train.loc[train_index,target],\n",
    "#                      cat_features=cat_features)\n",
    "# train_dataset.quantize()\n",
    "# train_dataset.save('../../data-vol-1/Prepared_data/train.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CatBoostRegressor()\n",
    "# #train the model\n",
    "# model.fit(train_dataset) \n",
    "# # # make the prediction using the resulting model\n",
    "# # preds_class = model.predict(test_pool, prediction_type='Class')\n",
    "# # preds_proba = model.predict(test_pool, prediction_type='Probability')\n",
    "# # preds_raw_vals = model.predict(test_pool, prediction_type='RawFormulaVal')\n",
    "# # print(\"Class\", preds_class)\n",
    "# # print(\"Proba\", preds_proba)\n",
    "# # print(\"Raw\", preds_raw_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pool = Pool(train.loc[train_index,features], \n",
    "#                   train.loc[train_index,target])\n",
    "\n",
    "# # test_pool = Pool(test_data) \n",
    "# # specify training parameters via map\n",
    "\n",
    "# param = {'iterations':5}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
