{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !pip install catboost\n",
    "# !pip install lightgbm\n",
    "# !pip install feather-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import random\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import feather\n",
    "import os\n",
    "import glob\n",
    "import csv   \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "path = '../data'\n",
    "train = feather.read_dataframe(f'{path}/Prepared_data/train_prepared.feather')\n",
    "# train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "train['meter_reading_log'] = np.log1p(train['meter_reading'])\n",
    "train.drop(columns=['utc','altitude','azimuth'], inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "train = train[(train['suspicious_1'] + train['suspicious_2']).eq(0)]\n",
    "train.drop(columns=['suspicious_1','suspicious_2'],inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "train['meter_median'] = train.groupby(['building_id','meter'])['meter_reading_log'].transform('median')\n",
    "train['meter_min'] = train.groupby(['building_id','meter'])['meter_reading_log'].transform('min')\n",
    "train['meter_max'] = train.groupby(['building_id','meter'])['meter_reading_log'].transform('max')\n",
    "train['meter_std'] = train.groupby(['building_id','meter'])['meter_reading_log'].transform('std')\n",
    "\n",
    "train['hour'] = train['timestamp'].dt.hour\n",
    "\n",
    "train['meter_hour_median'] = train.groupby(['building_id','meter','hour'])['meter_reading_log'].transform('median')\n",
    "train['meter_hour_min'] = train.groupby(['building_id','meter','hour'])['meter_reading_log'].transform('min')\n",
    "train['meter_hour_max'] = train.groupby(['building_id','meter','hour'])['meter_reading_log'].transform('max')\n",
    "train['meter_hour_std'] = train.groupby(['building_id','meter','hour'])['meter_reading_log'].transform('std')\n",
    "\n",
    "%%time\n",
    "# train.reset_index(drop=True).to_feather(f'../../data-vol-3/Prepared_data/train_prepared_subset.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# test = feather.read_dataframe(f'../../data-vol-3/Prepared_data/test_leaked_prepared.feather')\n",
    "# test.drop(columns=['utc','utc_time','altitude','azimuth'], inplace=True)\n",
    "# test.dropna(subset=['meter_reading'],inplace=True)\n",
    "# test = test[test['meter_reading']!=0].reset_index(drop=True)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# test = feather.read_dataframe(f\"{path}/Prepared_data/test_prepared.feather\")\n",
    "# test = test.set_index('row_id')\n",
    "# test = test.sort_index()\n",
    "# gc.collect()\n",
    "\n",
    "# leaked = feather.read_dataframe(f\"../../data-vol-3/Leaked_data/leaked_submission.feather\")\n",
    "# test = test.iloc[leaked['row_id'].values]\n",
    "# test['meter_reading'] = leaked['meter_reading']\n",
    "# test['meter_reading_log'] = np.log1p(test['meter_reading'])\n",
    "# test.reset_index(inplace=True)\n",
    "\n",
    "# del leaked\n",
    "# gc.collect()\n",
    "# test.to_feather(f'../../data-vol-3/Prepared_data/test_leaked_prepared.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['building_id',\n",
    "             'site_id',\n",
    "             'primary_use',\n",
    "             'square_feet',\n",
    "             'floor_count',\n",
    "             'new_floor_count',\n",
    "             'is_holiday',\n",
    "             'weekday_cos',\n",
    "             'weekday_sin',\n",
    "             'weekday',\n",
    "             'hour_cos',\n",
    "             'hour_sin',\n",
    "             'year_cos',\n",
    "             'year_sin',\n",
    "             'is_day_saving',\n",
    "             'air_temperature',\n",
    "             'age',\n",
    "             'dew_temperature',\n",
    "             'sea_level_pressure',\n",
    "             'new_dew_temperature',\n",
    "             'new_air_temperature',\n",
    "             'humidity',\n",
    "             'latitude',\n",
    "             'irradiance',\n",
    "             'feels_like',\n",
    "             'new_feels_like',\n",
    "             'radiation',\n",
    "             'air_temperature_mean_lag72',\n",
    "             'air_temperature_max_lag72',\n",
    "             'air_temperature_min_lag72',\n",
    "             'air_temperature_std_lag72',\n",
    "             'cloudCover_mean_lag72',\n",
    "             'cloudCover_std_lag72',\n",
    "             'meter_median',\n",
    "             'meter_max',\n",
    "             'meter_std',\n",
    "             'meter_hour_median',\n",
    "             'meter_hour_min',\n",
    "             'meter_hour_max',\n",
    "             'meter_hour_std'\n",
    "           ]\n",
    "#              'new_wind_speed',\n",
    "#              'new_sea_level_pressure',\n",
    "#              'new_wind_direction_sin'\n",
    "#              'new_wind_direction_cos',\n",
    "#              'meter_min',\n",
    "#              'meter',\n",
    "#              'wind_speed',\n",
    "#              'cloudCover',\n",
    "#              'longitude',\n",
    "#              'irradiance_cloud',\n",
    "#              'cloudCover_max_lag72',\n",
    "#              'wind_direction_cos',\n",
    "#              'wind_direction_sin',\n",
    "#              'new_year_built',\n",
    "#              'cloud_coverage',\n",
    "#              'precip_depth_1_hr',\n",
    "#              'cloudCover_min_lag72',\n",
    "#              'new_precip_depth_1_hr',\n",
    "#              'square_feet_log',\n",
    "#              'beaufort_scale',\n",
    "#              'suspicious_1',\n",
    "#              'suspicious_2',\n",
    "#              'year_built',\n",
    "#              'meter_reading',  \n",
    "#              'timestamp',\n",
    "#              'night_time',\n",
    "#              'morning',\n",
    "#              'afternoon',\n",
    "#              'evening',\n",
    "#              'new_cloud_coverage',\n",
    "#              'uvIndex',\n",
    "#              'meter_reading_log',\n",
    "#              'split']\n",
    "\n",
    "\n",
    "target = 'meter_reading_log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['primary_use','is_day_saving','is_holiday','building_id','meter','site_id']:\n",
    "    train[f] = train[f].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_split = 5\n",
    "version = 35\n",
    "model_name = 'lgbm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_method = 'stratified_site_id_week'\n",
    "train['split'] = (train['site_id'].astype(int) + train['utc_time'].dt.weekofyear - 1) % n_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params =  {\n",
    "    'objective': 'regression',\n",
    "#      'boosting_type': 'goss',\n",
    "#      'top_rate':0.5,\n",
    "#      'other_rate':0.2,\n",
    "     'boosting_type': 'gbdt',\n",
    "     'metric': 'rmse',\n",
    "     'n_jobs': -1,\n",
    "     'learning_rate': 0.05,\n",
    "     'num_leaves': 50,\n",
    "     'max_depth': 10,\n",
    "     'tree_learner': 'serial',\n",
    "     'subsample_freq': 1,\n",
    "     'subsample': 0.5,\n",
    "     'colsample_bytree': 0.5,\n",
    "     'max_bin': 50,\n",
    "     'verbose': 2,\n",
    "     'n_estimators':1000,\n",
    "     'seed': seed,\n",
    "#      'cat_l2':0.05,\n",
    "     'lambda_l2':0.1,\n",
    "     'early_stopping_rounds':100 }\n",
    "\n",
    "\n",
    "\n",
    "mean_performance_test = 0 \n",
    "mean_performance_train = 0\n",
    "mean_performance_leaked = 0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for meter in range(4):\n",
    "    print(f\"\\n===== Meter {meter} =====\")\n",
    "    for fold in range(5):  \n",
    "        print(f\"\\n===== Fold numer {fold} =====\\n\")\n",
    "        \n",
    "        index_train = train['split'].ne(fold) & train['meter'].eq(meter)\n",
    "        tr_data = lgb.Dataset(train.loc[index_train][features], \n",
    "                              label=train.loc[index_train][target])\n",
    "        \n",
    "        index_vl = train['split'].eq(fold) & train['meter'].eq(meter)\n",
    "        vl_data = lgb.Dataset(train.loc[index_vl][features], \n",
    "                              label=train.loc[index_vl][target])\n",
    "        \n",
    "        print(index_vl.sum(),index_train.sum())\n",
    "        del index_train,index_vl\n",
    "        gc.collect()\n",
    "        \n",
    "        estimator = lgb.train(\n",
    "                    lgb_params,\n",
    "                    tr_data,\n",
    "                    valid_sets = [tr_data,vl_data],\n",
    "                    verbose_eval = 50)\n",
    "        \n",
    "        model_filename = f'models/{model_name}_meter_{meter}_v_{version}_{cv_method}_fold_{fold}.bin'\n",
    "        \n",
    "        pickle.dump(estimator, open(model_filename, 'wb'))\n",
    "\n",
    "        performance_test = estimator.best_score['valid_1']['rmse']\n",
    "        performance_train = estimator.best_score['training']['rmse']\n",
    "\n",
    "        mean_performance_test += performance_test\n",
    "        mean_performance_train += performance_train\n",
    "\n",
    "    #     i = 0\n",
    "    #     step = 100000\n",
    "    #     test['pred'] = np.nan\n",
    "    #     while i < test.shape[0]:\n",
    "    #         test.loc[i:(i+step-1),'pred'] = estimator.predict(test.iloc[i:(i+step)][features])\n",
    "    #         i = i + step\n",
    "    #         gc.collect()\n",
    "    #     print(\"Done with the test prediction\")\n",
    "\n",
    "    #     performance_leaked = np.sqrt(mean_squared_error(test['meter_reading_log'],test['pred']))\n",
    "    #     mean_performance_leaked += performance_leaked\n",
    "    #     print((mean_performance_train/(fold+1)),(mean_performance_test/(fold+1)),(mean_performance_leaked/(fold+1)))\n",
    "\n",
    "        with open(r'./models/perf_leaked.csv', 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([model_filename, fold, performance_train, performance_test, 0, version])\n",
    "\n",
    "        print((mean_performance_train/(fold+1)),(mean_performance_test/(fold+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_performance_leaked = mean_performance_leaked/n_split\n",
    "mean_performance_test = mean_performance_test/n_split\n",
    "mean_performance_train = mean_performance_train/n_split\n",
    "\n",
    "with open(r'./models/perf_leaked.csv', 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([model_filename, 'avg', mean_performance_train, mean_performance_test, 0, version])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame({'Feature':estimator.feature_name()})\n",
    "\n",
    "for meter in range(4):\n",
    "    for i in range(n_split):\n",
    "        m = f'models/{model_name}_meter_{meter}_v_{version}_{cv_method}_fold_{i}.bin'\n",
    "        model = pickle.load(open(m,'rb'))\n",
    "        importance = f'Importance_{i}_{meter}'\n",
    "        feature_imp[importance] = model.feature_importance()\n",
    "        feature_imp[importance] = feature_imp[importance]*100/feature_imp[importance].max()\n",
    "\n",
    "feature_imp = feature_imp.set_index('Feature').stack().reset_index()\n",
    "feature_imp['meter'] = feature_imp['level_1'].apply(lambda x: x.split('_')[2])\n",
    "feature_imp['fold'] = feature_imp['level_1'].apply(lambda x: x.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = feature_imp.groupby(['meter','Feature'])[0].agg(['mean','max'])\n",
    "s = s.reset_index()\n",
    "s = s.pivot(index='Feature',values='mean', columns='meter')\n",
    "s = s.sort_values('3',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s.plot(figsize=(40, 20), kind='bar')\n",
    "plt.title('LightGBM Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 20))\n",
    "sns.set(font_scale = 3)\n",
    "sns.barplot(x=\"max\", y=\"Feature\", data=feature_imp.sort_values(by=\"max\", \n",
    "                                                    ascending=False).reset_index(), color='C0')\n",
    "\n",
    "plt.title('LightGBM Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp.to_csv(f'./models/feature_importance_v_{version}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(4):\n",
    "    \n",
    "    tr_data = lgb.Dataset(train[train['meter'].eq(m)][features],\n",
    "                          label=train[train['meter'].eq(m)][target])\n",
    "\n",
    "    gc.collect()\n",
    "    estimator = lgb.train(\n",
    "                lgb_params,\n",
    "                tr_data,\n",
    "                valid_sets = [tr_data],\n",
    "                verbose_eval = 50)\n",
    "\n",
    "    model_filename = f'models/{model_name}_meter_{m}_v_{version}_all.bin'\n",
    "\n",
    "    pickle.dump(estimator, open(model_filename, 'wb'))\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
